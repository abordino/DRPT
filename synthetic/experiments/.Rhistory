need = pkgs[!sapply(pkgs, requireNamespace, quietly = TRUE)]
if (length(need) > 0) install.packages(need)
invisible(lapply(pkgs, library, character.only = TRUE))
set.seed(170966)
# -------------------
# DGP definitions
# -------------------
p = 10
rho = 0.5
Sigma = outer(1:p, 1:p, function(i,j) rho^abs(i-j))  # AR(1)
beta0 = 0
beta  = c(0.6, -0.5, 0.4, 0.3, -0.2, 0.1, 0.25, -0.15, 0.2, -0.25)
expit = function(x) 1/(1+exp(-x))
eta_gamma = function(Z, gamma) {
drop(beta0 + Z %*% beta) + gamma * ( sin(10 * Z[,1]) + Z[,2] * Z[,3] )
}
draw_joint = function(N, gamma) {
Z = MASS::mvrnorm(N, mu = rep(0, p), Sigma = Sigma)
e = expit(eta_gamma(Z, gamma))
D = rbinom(N, 1, e)
list(Z = Z, D = D)
}
draw_groups_fixed = function(n0, n1, gamma) {
Z0 = NULL; Z1 = NULL
while (is.null(Z0) || nrow(Z0) < n0 || is.null(Z1) || nrow(Z1) < n1) {
S = draw_joint(4000, gamma)
Z0 = rbind(Z0, S$Z[S$D==0, , drop = FALSE])
Z1 = rbind(Z1, S$Z[S$D==1, , drop = FALSE])
}
list(X = Z0[1:n0, , drop = FALSE],  # f = Z|D=0
Y = Z1[1:n1, , drop = FALSE])  # g = Z|D=1
}
# -------------------
# Kernel for DRPT
# -------------------
gaussian.kernel = function(x, y, lambda = 1) {
d = length(x)
lambda^(-d) * exp(-sum((x - y)^2) / (lambda^2))
}
# -------------------
# Ratio estimator: Linear Logistic
# -------------------
fit_ratio_LL = function(N_train, gamma) {
S = draw_joint(N_train, gamma)
Z = S$Z; D = S$D
df = as.data.frame(Z); colnames(df) = paste0("z", 1:ncol(Z))
df$D = factor(D)
pi_train = mean(D)
fml = as.formula(paste("D ~", paste(colnames(df)[1:p], collapse = " + ")))
glm_fit = glm(fml, data = df, family = binomial())
# rhat(z) = exp(eta_hat(z) - logit(pi_train)) = ((1-pi)/pi)*odds
rhat = function(...) {
Znew = cbind(...)
if (is.null(dim(Znew))) Znew = matrix(Znew, nrow = 1)
Zdf = as.data.frame(Znew)
colnames(Zdf) = paste0("z", 1:ncol(Znew))
phat = predict(glm_fit, newdata = Zdf, type = "response")
phat = pmin(pmax(phat, 1e-12), 1 - 1e-12)
odds = phat / (1 - phat)
exp(-qlogis(pi_train)) * odds
}
rhat
}
create_lookup_list = function(X, rX, Y, rY) {
keysX = apply(X, 1, paste, collapse = "_")
keysY = apply(Y, 1, paste, collapse = "_")
lookup_list = setNames(as.list(c(rX, rY)), c(keysX, keysY))
return(lookup_list)
}
# -------------------
# Experiment config
# -------------------
gammas = c(0, 0.25, 0.5, 1, 2)
N_train = 1000                 # training size for ratio
N_test_per_group = 150         # if n=m=100 => total 200 in test
MC = 200                       # repetitions per gamma
alpha_level = 0.05
# output dir
out_dir = file.path(getwd(), "experiments", "results")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
# -------------------
# Run experiment
# -------------------
results = list()
rowid = 1
for (g in gammas) {
message(sprintf("Gamma = %s", g))
# Fit ratio once per gamma on independent training data
rfun = fit_ratio_LL(N_train = N_train, gamma = g)
rej_count = 0
for (b in seq_len(MC)) {
G = draw_groups_fixed(n0 = N_test_per_group, n1 = N_test_per_group, gamma = g)
X = G$X; Y = G$Y
lookup_table = create_lookup_list(X, rfun(X), Y, rfun(Y))
r.hat = function(...) {
z = cbind(...)
if (is.matrix(z) || is.data.frame(z)) {
keys = apply(z, 1, paste, collapse = "_")
return(sapply(keys, function(key) ifelse(key %in% names(lookup_table), lookup_table[[key]], NA)))
} else {
key = paste(z, collapse = "_")
return(ifelse(key %in% names(lookup_table), lookup_table[[key]], NA))
}
}
lam = kerTests::med_sigma(X, Y)
kfun = function(x, y) gaussian.kernel(x, y, lambda = lam)
pval = DRPT::DRPT(X, Y, r = r.hat, kernel = kfun)
decision = as.integer(pval < alpha_level)
results[[rowid]] = data.frame(gamma = g, rep = b,
p_value = as.numeric(pval),
decision = decision)
rowid = rowid + 1
rej_count = rej_count + decision
}
power_g = rej_count / MC
message(sprintf("  -> Power estimate: %.3f", power_g))
}
# ==========================================
# Causal DGP, KLR ratio (IRLS only, NO SCALING), DRPT (E1), save decisions
# ==========================================
rm(list = ls()); gc()
# --- (optional) working dir ---
# setwd("~/Documents/phd/projects/DRPT/code/simulationCpp/propensityCausal/")
# --- deps ---
pkgs = c("MASS","DRPT","kerTests", "calibrateBinary", "CVST")
need = pkgs[!sapply(pkgs, requireNamespace, quietly = TRUE)]
if (length(need) > 0) install.packages(need)
invisible(lapply(pkgs, library, character.only = TRUE))
set.seed(170966)
# -------------------
# DGP definitions
# -------------------
p = 10
rho = 0.5
Sigma = outer(1:p, 1:p, function(i,j) rho^abs(i-j))  # AR(1)
beta0 = 0
beta  = c(0.6, -0.5, 0.4, 0.3, -0.2, 0.1, 0.25, -0.15, 0.2, -0.25)
expit = function(x) 1/(1+exp(-x))
eta_gamma = function(Z, gamma) {
drop(beta0 + Z %*% beta) + gamma * ( sin(10 * Z[,1]) + Z[,2] * Z[,3] )
}
draw_joint = function(N, gamma) {
Z = MASS::mvrnorm(N, mu = rep(0, p), Sigma = Sigma)
e = expit(eta_gamma(Z, gamma))
D = rbinom(N, 1, e)
list(Z = Z, D = D)
}
# exact group sizes for DRPT comparisons
draw_groups_fixed = function(n0, n1, gamma) {
Z0 = NULL; Z1 = NULL
while (is.null(Z0) || nrow(Z0) < n0 || is.null(Z1) || nrow(Z1) < n1) {
S = draw_joint(4000, gamma)
Z0 = rbind(Z0, S$Z[S$D==0, , drop = FALSE])
Z1 = rbind(Z1, S$Z[S$D==1, , drop = FALSE])
}
list(X = Z0[1:n0, , drop = FALSE],  # f = Z|D=0
Y = Z1[1:n1, , drop = FALSE])  # g = Z|D=1
}
# -------------------
# Kernel for DRPT (uses length-scale lambda)
# -------------------
gaussian.kernel = function(x, y, lambda = 1) {
d = length(x)
lambda^(-d) * exp(-sum((x - y)^2) / (lambda^2))
}
# -------------------
# Ratio estimator: Kernel Linear Logistic (with prior correction)
# -------------------
fit_ratio_KLR = function(N_train, gamma,
params = list(kernel = "rbfdot",
sigma  = 0.005,     # kernlab gamma
lambda = 0.0005,    # NOTE: CVST multiplies by N internally
tol    = 1e-6,
maxiter= 500)) {
# draw and split (as in your LL helper)
S = draw_joint(N_train, gamma)
Z = S$Z; D = S$D
Xf = Z[D == 0, , drop = FALSE]
Xg = Z[D == 1, , drop = FALSE]
nf = nrow(Xf); ng = nrow(Xg)
if (nf < 10 || ng < 10) return(NULL)
# pool + labels as factor {0,1} (CVST expects a factor for classification)
x.fit    = rbind(Xf, Xg)
label.fit= factor(c(rep(0, nf), rep(1, ng)))
# build CVST data + learner, train with your params
klrlearner = CVST::constructKlogRegLearner()
data.fit   = CVST::constructData(x.fit, label.fit)
# IMPORTANT: In CVST, the learner multiplies lambda by N internally.
# If you want an *effective* lambda = L, set params$lambda = L / nrow(x.fit).
fit = klrlearner$learn(data.fit, params)
# ratio estimator r(x) = (nf/ng) * odds(x), odds = p/(1-p)
rhat = function(...) {
newX = cbind(...)
if (is.null(dim(newX))) newX = matrix(newX, nrow = 1)
# f(x) via kernel expansion, then sigmoid
fx  = kernlab::kernelMult(fit$kernel, newX, fit$data, fit$alpha)
p   = 1 / (1 + exp(-as.vector(fx)))
p   = pmin(pmax(p, 1e-12), 1 - 1e-12)
odds = p / (1 - p)
out  = (nf / ng) * odds
pmin(pmax(as.numeric(out), 1e-12), 1e12)
}
rhat
}
create_lookup_list = function(X, rX, Y, rY) {
keysX = apply(X, 1, paste, collapse = "_")
keysY = apply(Y, 1, paste, collapse = "_")
lookup_list = setNames(as.list(c(rX, rY)), c(keysX, keysY))
return(lookup_list)
}
# -------------------
# Experiment config
# -------------------
gammas = c(0, 0.25, 0.5, 1, 2)
N_train = 1000                 # training size for ratio
N_test_per_group = 150         # n=m=100
MC = 1                       # repetitions per gamma
alpha_level = 0.05
# output dir
out_dir = file.path(getwd(), "experiments", "results")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
# -------------------
# Run experiment
# -------------------
results = list()
rowid = 1
for (g in gammas) {
message(sprintf("Gamma = %s", g))
# Fit KLR ratio once per gamma on independent training data (IRLS, no scaling)
rfun = fit_ratio_KLR(N_train = N_train, gamma = g)
rej_count = 0
valid_reps = 0
for (b in seq_len(MC)) {
G = draw_groups_fixed(n0 = N_test_per_group, n1 = N_test_per_group, gamma = g)
X = G$X; Y = G$Y
lookup_table = create_lookup_list(X, rfun(X), Y, rfun(Y))
rhat = function(...) {
z = cbind(...)
if (is.matrix(z) || is.data.frame(z)) {
keys = apply(z, 1, paste, collapse = "_")
return(sapply(keys, function(key) ifelse(key %in% names(lookup_table), lookup_table[[key]], NA)))
} else {
key = paste(z, collapse = "_")
return(ifelse(key %in% names(lookup_table), lookup_table[[key]], NA))
}
}
# DRPT kernel bandwidth from RAW test features
lam = kerTests::med_sigma(X, Y)
kfun = function(x, y) gaussian.kernel(x, y, lambda = lam)
pval = DRPT::DRPT(X, Y, r = r.hat, kernel = kfun)
decision = as.integer(pval < alpha_level)
results[[rowid]] = data.frame(gamma = g, rep = b,
p_value = as.numeric(pval),
decision = decision)
rowid = rowid + 1
}
power_g = if (valid_reps > 0) rej_count / valid_reps else NA_real_
message(sprintf("  -> Power estimate (na.rm): %.3f over %d valid reps",
ifelse(is.na(power_g), NaN, power_g), valid_reps))
}
rfun(X)
# ==========================================
# Causal DGP, KLR ratio (IRLS only, NO SCALING), DRPT (E1), save decisions
# ==========================================
rm(list = ls()); gc()
# --- (optional) working dir ---
# setwd("~/Documents/phd/projects/DRPT/code/simulationCpp/propensityCausal/")
# --- deps ---
pkgs = c("MASS","DRPT","kerTests", "calibrateBinary", "CVST")
need = pkgs[!sapply(pkgs, requireNamespace, quietly = TRUE)]
if (length(need) > 0) install.packages(need)
invisible(lapply(pkgs, library, character.only = TRUE))
set.seed(170966)
# -------------------
# DGP definitions
# -------------------
p = 10
rho = 0.5
Sigma = outer(1:p, 1:p, function(i,j) rho^abs(i-j))  # AR(1)
beta0 = 0
beta  = c(0.6, -0.5, 0.4, 0.3, -0.2, 0.1, 0.25, -0.15, 0.2, -0.25)
expit = function(x) 1/(1+exp(-x))
eta_gamma = function(Z, gamma) {
drop(beta0 + Z %*% beta) + gamma * ( sin(10 * Z[,1]) + Z[,2] * Z[,3] )
}
draw_joint = function(N, gamma) {
Z = MASS::mvrnorm(N, mu = rep(0, p), Sigma = Sigma)
e = expit(eta_gamma(Z, gamma))
D = rbinom(N, 1, e)
list(Z = Z, D = D)
}
# exact group sizes for DRPT comparisons
draw_groups_fixed = function(n0, n1, gamma) {
Z0 = NULL; Z1 = NULL
while (is.null(Z0) || nrow(Z0) < n0 || is.null(Z1) || nrow(Z1) < n1) {
S = draw_joint(4000, gamma)
Z0 = rbind(Z0, S$Z[S$D==0, , drop = FALSE])
Z1 = rbind(Z1, S$Z[S$D==1, , drop = FALSE])
}
list(X = Z0[1:n0, , drop = FALSE],  # f = Z|D=0
Y = Z1[1:n1, , drop = FALSE])  # g = Z|D=1
}
# -------------------
# Kernel for DRPT (uses length-scale lambda)
# -------------------
gaussian.kernel = function(x, y, lambda = 1) {
d = length(x)
lambda^(-d) * exp(-sum((x - y)^2) / (lambda^2))
}
# -------------------
# Ratio estimator: Kernel Linear Logistic (with prior correction)
# -------------------
fit_ratio_KLR = function(N_train, gamma,
params = list(kernel = "rbfdot",
sigma  = 0.005,
lambda = 0.0005,
tol    = 1e-6,
maxiter= 500)) {
# draw and split
S = draw_joint(N_train, gamma)
Z = S$Z; D = S$D
Xf = Z[D == 0, , drop = FALSE]
Xg = Z[D == 1, , drop = FALSE]
nf = nrow(Xf); ng = nrow(Xg)
if (nf < 10 || ng < 10) return(NULL)
# pool + labels as factor {0,1}
x.fit    = rbind(Xf, Xg)
label.fit= factor(c(rep(0, nf), rep(1, ng)))
# build CVST data + learner, train with your params
klrlearner = CVST::constructKlogRegLearner()
data.fit   = CVST::constructData(x.fit, label.fit)
fit = klrlearner$learn(data.fit, params)
# ratio estimator r(x) = (nf/ng) * odds(x), odds = p/(1-p)
rhat = function(...) {
newX = cbind(...)
if (is.null(dim(newX))) newX = matrix(newX, nrow = 1)
# f(x) via kernel expansion, then sigmoid
fx  = kernlab::kernelMult(fit$kernel, newX, fit$data, fit$alpha)
p   = 1 / (1 + exp(-as.vector(fx)))
p   = pmin(pmax(p, 1e-12), 1 - 1e-12)
odds = p / (1 - p)
out  = (nf / ng) * odds
pmin(pmax(as.numeric(out), 1e-12), 1e12)
}
rhat
}
create_lookup_list = function(X, rX, Y, rY) {
keysX = apply(X, 1, paste, collapse = "_")
keysY = apply(Y, 1, paste, collapse = "_")
lookup_list = setNames(as.list(c(rX, rY)), c(keysX, keysY))
return(lookup_list)
}
# -------------------
# Experiment config
# -------------------
gammas = c(0, 0.25, 0.5, 1, 2)
N_train = 1000                 # training size for ratio
N_test_per_group = 150         # n=m=100
MC = 1                       # repetitions per gamma
alpha_level = 0.05
# output dir
out_dir = file.path(getwd(), "experiments", "results")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
# -------------------
# Run experiment
# -------------------
results = list()
rowid = 1
for (g in gammas) {
message(sprintf("Gamma = %s", g))
# Fit KLR ratio once per gamma on independent training data (IRLS, no scaling)
rfun = fit_ratio_KLR(N_train = N_train, gamma = g)
rej_count = 0
valid_reps = 0
for (b in seq_len(MC)) {
G = draw_groups_fixed(n0 = N_test_per_group, n1 = N_test_per_group, gamma = g)
X = G$X; Y = G$Y
lookup_table = create_lookup_list(X, rfun(X), Y, rfun(Y))
r.hat = function(...) {
z = cbind(...)
if (is.matrix(z) || is.data.frame(z)) {
keys = apply(z, 1, paste, collapse = "_")
return(sapply(keys, function(key) ifelse(key %in% names(lookup_table), lookup_table[[key]], NA)))
} else {
key = paste(z, collapse = "_")
return(ifelse(key %in% names(lookup_table), lookup_table[[key]], NA))
}
}
# DRPT kernel bandwidth from RAW test features
lam = kerTests::med_sigma(X, Y)
kfun = function(x, y) gaussian.kernel(x, y, lambda = lam)
pval = DRPT::DRPT(X, Y, r = r.hat, kernel = kfun)
decision = as.integer(pval < alpha_level)
results[[rowid]] = data.frame(gamma = g, rep = b,
p_value = as.numeric(pval),
decision = decision)
rowid = rowid + 1
}
power_g = if (valid_reps > 0) rej_count / valid_reps else NA_real_
message(sprintf("  -> Power estimate (na.rm): %.3f over %d valid reps",
ifelse(is.na(power_g), NaN, power_g), valid_reps))
}
# Combine pictures (optional)
library(magick)
# Paths and labels
files  = c("experiments/pictures/BIVsimul_shiftedMMD.png",
"experiments/pictures/binary.png",
"experiments/pictures/DRPT_excessGaussian.png")
labels = c("(a)", "(b)", "(c)")
# Read images
imgs = image_read(files)
rm(list = ls())  # Clear environment
gc()             # Free memory
# setwd("~/Documents/phd/distr_shift/simulationCpp/synthetic")
setwd("~/Documents/phd/projects/DRPT/code/simulationCpp/synthetic/")
library(MASS)
library(latex2exp)
library(squash)
library(DRPT)
library(kerTests)
set.seed(110932)
# ------------------------------------------
# Combine pictures
# ------------------------------------------
library(magick)
# Paths and labels
files  = c("experiments/pictures/BIVsimul_shiftedMMD.png",
"experiments/pictures/binary.png",
"experiments/pictures/DRPT_excessGaussian.png")
labels = c("(a)", "(b)", "(c)")
# Read images
imgs = image_read(files)
# Make heights match
info      = image_info(imgs)
target_h  = min(info$height)
imgs_eqh  = image_scale(imgs, paste0("x", target_h))
# Helper to add corner label
label_img = function(img, lab, corner = "northwest", inset = 20, size = NULL) {
if (is.null(size)) {
h = image_info(img)$height
size = max(18, round(h * 0.05))
}
image_annotate(
img, lab,
gravity   = corner,                 # "northwest" = top-left
location  = paste0("+", inset, "+", inset),
size      = size,
weight    = 700,
color     = "black",
boxcolor  = "rgba(255,255,255,0.7)" # soft white box for readability
)
}
# Add (a), (b), (c)
labeled = Map(label_img, imgs_eqh, labels)
# ------------------------------------------
# Combine pictures
# ------------------------------------------
library(magick)
# Files and labels
files  = c("experiments/pictures/BIVsimul_shiftedMMD.png",
"experiments/pictures/binary.png",
"experiments/pictures/DRPT_excessGaussian.png")
labels = c("(a)", "(b)", "(c)")
# Read images
imgs = image_read(files)
# Normalize heights to the smallest height (to keep aspect ratios)
info     = image_info(imgs)
target_h = min(info$height)
imgs_eqh = image_scale(imgs, paste0("x", target_h))
# Helper: add a corner label
label_img = function(img, lab, corner = "northwest", inset = 20, size = NULL) {
if (is.null(size)) {
h = image_info(img)$height
size = max(18, round(h * 0.05))
}
image_annotate(
img, lab,
gravity  = corner,                 # "northwest" = top-left
location = paste0("+", inset, "+", inset),
size     = size,
weight   = 700,
color    = "black",
boxcolor = "rgba(255,255,255,0.7)"
)
}
# Label each image (ensure each element is a magick-image)
labeled = lapply(seq_along(labels), function(i) {
label_img(imgs_eqh[i], labels[i])
})
# Combine pictures with simple text labels
library(magick)
imgs = image_read(c("experiments/pictures/BIVsimul_shiftedMMD.png",
"experiments/pictures/binary.png",
"experiments/pictures/DRPT_excessGaussian.png"))
# Add (a), (b), (c) in the top-left corner of each image
a = image_annotate(imgs[1], "(a)", size = 30, color = "black",
boxcolor = "white", gravity = "northwest",
location = "+15+15")
setwd("~/Documents/phd/projects/DRPT/code/simulationCpp/synthetic/experiments")
# Combine pictures with simple text labels
library(magick)
imgs = image_read(c("experiments/pictures/BIVsimul_shiftedMMD.png",
"experiments/pictures/binary.png",
"experiments/pictures/DRPT_excessGaussian.png"))
imgs = image_read(c("experiments/pictures/BIVsimul_shiftedMMD.png",
"experiments/pictures/binary.png",
"experiments/pictures/DRPT_excessGaussian.png"))
# Combine pictures with simple text labels
library(magick)
imgs = image_read(c("experiments/pictures/BIVsimul_shiftedMMD.png",
"experiments/pictures/binary.png",
"experiments/pictures/DRPT_excessGaussian.png"))
